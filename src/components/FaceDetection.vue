<script setup lang="ts">
import { ref, onMounted, onUnmounted, defineEmits } from "vue";
import { loadModels, getForeheadRegion } from "../utils/faceDetection";
import { getHeartRateFromROI } from "../utils/getHeartRate";

const emit = defineEmits(["updateHeartRate"]);

const video = ref<HTMLVideoElement | null>(null);
const canvas = ref<HTMLCanvasElement | null>(null);
let animationFrameId: number | null = null;
const rgbValues: number[] = [];
let isCameraActive = false;

/**
 * é¡ã®æ ã‚’æç”»ã™ã‚‹é–¢æ•°
 */
const drawForeheadBox = async () => {
  if (!video.value || !canvas.value) return;

  const ctx = canvas.value.getContext("2d");
  if (!ctx) {
    console.error("Canvas ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒå–å¾—ã§ãã¾ã›ã‚“");
    return;
  }

  canvas.value.width = video.value.videoWidth || 640;
  canvas.value.height = video.value.videoHeight || 480;

  const offscreenCanvas = new OffscreenCanvas(canvas.value.width, canvas.value.height);
  const offscreenCtx = offscreenCanvas.getContext("2d");

  const update = async () => {
    if (!video.value || !canvas.value || !offscreenCtx || !isCameraActive) return;

    const forehead = await getForeheadRegion(video.value);
    if (forehead) {
      offscreenCtx.clearRect(0, 0, offscreenCanvas.width, offscreenCanvas.height);
      offscreenCtx.drawImage(video.value, 0, 0, offscreenCanvas.width, offscreenCanvas.height);

      const margin = 5;
      const roiX = forehead.x + margin;
      const roiY = forehead.y + margin;
      const roiWidth = forehead.width - margin * 2;
      const roiHeight = forehead.height - margin * 2;

      const imageData = offscreenCtx.getImageData(roiX, roiY, roiWidth, roiHeight);
      const data = imageData.data;

      let gTotal = 0;
      for (let i = 0; i < data.length; i += 4) {
        gTotal += data[i + 1]; // Gãƒãƒ£ãƒãƒ«
      }

      const gAvg = gTotal / (data.length / 4);
      rgbValues.push(gAvg);

      if (rgbValues.length > 300) rgbValues.shift();

      if (rgbValues.length >= 150) {
        const bpm = getHeartRateFromROI(rgbValues);
        console.log(`æ¨å®šè„ˆæ‹: ${Math.round(bpm)} bpm`);
        emit("updateHeartRate", Math.round(bpm));
      }

      ctx.clearRect(0, 0, canvas.value.width, canvas.value.height);
      ctx.strokeStyle = "red";
      ctx.lineWidth = 2;
      ctx.strokeRect(forehead.x, forehead.y, forehead.width, forehead.height);
    } else {
      console.warn("é¡ã®åº§æ¨™ãŒå–å¾—ã§ãã¾ã›ã‚“");
    }

    animationFrameId = requestAnimationFrame(update);
  };

  update();
};

/**
 * ã‚«ãƒ¡ãƒ©ã‚’é–‹å§‹ã™ã‚‹é–¢æ•°
 */
const startCamera = async () => {
  if (!video.value) return;

  try {
    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
    video.value.srcObject = stream;
    video.value.play().then(() => {
      isCameraActive = true;
      drawForeheadBox();
    }).catch(err => {
      console.error("å‹•ç”»å†ç”Ÿã‚¨ãƒ©ãƒ¼:", err);
    });
  } catch (error) {
    console.error("ã‚«ãƒ¡ãƒ©ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ", error);
  }
};

/**
 * ã‚«ãƒ¡ãƒ©ã‚’åœæ­¢ã™ã‚‹é–¢æ•°
 */
 const stopCamera = () => {
  if (!video.value || !video.value.srcObject) return;

  const stream = video.value.srcObject as MediaStream;
  stream.getTracks().forEach(track => track.stop());

  video.value.srcObject = null;
  isCameraActive = false;

  if (animationFrameId !== null) {
    cancelAnimationFrame(animationFrameId);
    animationFrameId = null;
  }

  // ğŸ”¹ ã‚­ãƒ£ãƒ³ãƒã‚¹ã®å†…å®¹ã‚’ã‚¯ãƒªã‚¢
  const ctx = canvas.value?.getContext("2d");
  if (ctx) {
    ctx.clearRect(0, 0, canvas.value!.width, canvas.value!.height);
  }
};

onMounted(async () => {
  await loadModels();
});

onUnmounted(() => {
  stopCamera();
});
</script>
<template>
  <div class="container">
    <div class="video-wrapper">
      <video ref="video" autoplay playsinline></video>
      <canvas ref="canvas"></canvas>
    </div>

    <div class="controls">
      <button @click="startCamera">ã‚«ãƒ¡ãƒ©é–‹å§‹</button>
      <button @click="stopCamera">ã‚«ãƒ¡ãƒ©åœæ­¢</button>
    </div>
  </div>
</template>

<style scoped>
.container {
  display: flex;
  flex-direction: column;
  align-items: center; /* ä¸­å¤®é…ç½® */
  gap: 16px; /* è¦ç´ é–“ã®ä½™ç™½ */
}

.video-wrapper {
  position: relative;
  width: 640px; /* ãƒ“ãƒ‡ã‚ªã®å¹…ã‚’å›ºå®š */
  height: 480px; /* ãƒ“ãƒ‡ã‚ªã®é«˜ã•ã‚’å›ºå®š */
  border: 2px solid #ddd; /* ãƒ“ãƒ‡ã‚ªæ ã®è¦–èªæ€§ã‚’å‘ä¸Š */
  border-radius: 12px;
  overflow: hidden; /* ã¯ã¿å‡ºã—é˜²æ­¢ */
  box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2); /* ç«‹ä½“æ„Ÿ */
}

video, canvas {
  position: absolute;
  top: 0;
  left: 0;
}

.controls {
  display: flex;
  gap: 12px;
}

button {
  background-color: #4CAF50;
  color: white;
  border: none;
  padding: 10px 20px;
  border-radius: 8px;
  cursor: pointer;
  transition: background 0.3s ease;
}

button:hover {
  background-color: #45a049;
}

button:disabled {
  background-color: #aaa;
  cursor: not-allowed;
}
</style>